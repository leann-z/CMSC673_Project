{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdMlBcwGXuP7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import OneClassSVM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'cleaned_electricity_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyNDyMJ8YN1u",
        "outputId": "99d010ea-0f14-41b2-d7fd-8992a7d619ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            CONS_NO  FLAG  2014/1/1  2014/1/10  2014/1/11  \\\n",
            "0  0387DD8A07E07FDA6271170F86AD9151     1       0.0       0.00       0.00   \n",
            "1  01D6177B5D4FFE0CABA9EF17DAFC2B84     1       0.0       0.00       0.00   \n",
            "2  4B75AC4F2D8434CFF62DB64D0BB43103     1       0.0       0.00       0.00   \n",
            "3  B32AC8CC6D5D805AC053557AB05F5343     1       0.0       0.00       0.00   \n",
            "4  EDFC78B07BA2908B3395C4EB2304665E     1       2.9       3.42       3.81   \n",
            "\n",
            "   2014/1/12  2014/1/13  2014/1/14  2014/1/15  2014/1/16  ...  2016/9/29  \\\n",
            "0       0.00       0.00       0.00       0.00       0.00  ...       9.96   \n",
            "1       0.00       0.00       0.00       0.00       0.00  ...       0.00   \n",
            "2       0.00       0.00       0.00       0.00       0.00  ...       0.00   \n",
            "3       0.00       0.00       0.00       0.00       0.00  ...       9.99   \n",
            "4       4.58       3.56       4.25       3.86       3.53  ...      10.37   \n",
            "\n",
            "   2016/9/3  2016/9/30  2016/9/4  2016/9/5  2016/9/6  2016/9/7  2016/9/8  \\\n",
            "0     16.92       7.60     27.22     18.05     26.47     18.75     17.84   \n",
            "1      0.00       0.00      0.00      0.00      0.00      0.00      0.00   \n",
            "2      0.00       0.00      0.00      0.00      0.00      0.00      0.00   \n",
            "3     11.78      18.59     26.80     18.57     14.59     12.82     19.37   \n",
            "4     15.32      13.51     12.23     14.68     16.35     18.14     18.41   \n",
            "\n",
            "   2016/9/9  total_consumption  \n",
            "0     14.92            8213.92  \n",
            "1      0.00               0.00  \n",
            "2      0.00            2569.64  \n",
            "3     15.92            6896.89  \n",
            "4     17.31            8497.23  \n",
            "\n",
            "[5 rows x 1037 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "YsRZQSJy9Neo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, 2:-1]  # all columns except the 'FLAG' and 'CONSUMER_ID'\n",
        "y = df['FLAG']        # the anomaly flag column\n"
      ],
      "metadata": {
        "id": "bSEVP5-m5aOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape data to match LSTM expected input shape (samples, time steps, features)\n",
        "time_steps = 30  #  a time window of 30 days for prediction\n",
        "X_sequences = []\n",
        "\n",
        "for i in range(time_steps, X_scaled.shape[0]):\n",
        "    X_sequences.append(X_scaled[i - time_steps:i, :])\n",
        "\n",
        "X_sequences = np.array(X_sequences)\n",
        "y_sequences = y[time_steps:].values\n"
      ],
      "metadata": {
        "id": "EmnYp2N367d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, activation='relu', input_shape=(X_sequences.shape[1], X_sequences.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(X_sequences, y_sequences, epochs=10, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iXwAE-Z7GM9",
        "outputId": "7f3e9526-5fa1-4b3c-ceaa-9156749feb76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 64ms/step - loss: 1.2585 - val_loss: 0.2369\n",
            "Epoch 2/10\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0893 - val_loss: 0.0293\n",
            "Epoch 3/10\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0229 - val_loss: 0.0080\n",
            "Epoch 4/10\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0142 - val_loss: 0.0020\n",
            "Epoch 5/10\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0122 - val_loss: 0.0014\n",
            "Epoch 6/10\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0094 - val_loss: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0088 - val_loss: 7.1655e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0069 - val_loss: 0.0022\n",
            "Epoch 9/10\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0012\n",
            "Epoch 10/10\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0017\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f1a4b0bf4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features by getting the output of the last Dense layer\n",
        "feature_extractor = Sequential(model.layers[:-1])  # Removing the output layer to get intermediate features\n",
        "X_features = feature_extractor.predict(X_sequences)\n",
        "\n",
        "# Print a sample of the extracted features\n",
        "print(\"Extracted Features Shape:\", X_features.shape)\n",
        "print(\"Extracted Features (first 5 samples):\")\n",
        "print(X_features[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cJbvv8-7LBj",
        "outputId": "5dee2a17-1343-4e05-80c5-7b81692c2bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "Extracted Features Shape: (2042, 10)\n",
            "Extracted Features (first 5 samples):\n",
            "[[0.38635355 0.25735572 0.16999331 0.17480128 0.         0.37769836\n",
            "  0.15511006 0.05177077 0.31398988 0.        ]\n",
            " [0.37446958 0.26298475 0.18496445 0.18253282 0.         0.38744682\n",
            "  0.14893351 0.05569894 0.30963832 0.        ]\n",
            " [0.36682892 0.2690866  0.19528565 0.1884736  0.         0.38966894\n",
            "  0.14271034 0.05824789 0.3074931  0.        ]\n",
            " [0.35761344 0.26483947 0.19284377 0.18421258 0.         0.39511377\n",
            "  0.14416952 0.06248213 0.30878794 0.        ]\n",
            " [0.35886446 0.2600603  0.18248373 0.17988916 0.         0.3935637\n",
            "  0.15016992 0.06582925 0.31927687 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split for SVM\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Class distribution of y_train:\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize and train the OneClassSVM\n",
        "# svm_model = OneClassSVM(kernel='rbf', gamma='auto', nu=0.05)  # Adjust nu based on the expected percentage of anomalies\n",
        "# svm_model.fit(X_train)\n",
        "\n",
        "# # Predict anomalies on the test set\n",
        "# y_pred = svm_model.predict(X_test)\n",
        "# y_pred = np.where(y_pred == -1, 1, 0)  # Convert -1 to 1 (anomaly), 1 to 0 (normal)\n",
        "\n",
        "# 4. Alternative model: Random Forest\n",
        "# rf_model = RandomForestClassifier(class_weight='balanced')\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10, random_state=42)\n",
        "rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred = rf_model.predict(X_test)\n",
        "# cv_scores = cross_val_score(rf_model, X_train_resampled, y_train_resampled, cv=5)\n",
        "# print(f\"Cross-validation scores: {cv_scores}\")\n",
        "# print(f\"Mean CV score: {cv_scores.mean()}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bPAYSkf3Ivht",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "f6c1ab40-0b97-4d1b-d19c-655639e32254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_test_split' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2cab05671cf4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train-test split for SVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class distribution of y_train:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# print(\"Confusion Matrix:\")\n",
        "# print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# print(\"\\nClassification Report:\")\n",
        "# print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "n0M7vTrcI6IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nConfusion Matrix (RandomForest):\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report (RandomForest):\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "Sy_faZm2O-57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Selecting a subset of predictions and actual labels for simplicity\n",
        "subset_size = 50  # Adjust this size if you want a larger subset\n",
        "y_test_subset = y_test[:subset_size]\n",
        "y_pred_subset = y_pred[:subset_size]\n",
        "\n",
        "# Define indices for each case\n",
        "correct_anomalies = np.where((y_test_subset == 1) & (y_pred_subset == 1))[0]  # True Positives\n",
        "missed_anomalies = np.where((y_test_subset == 1) & (y_pred_subset == 0))[0]   # False Negatives\n",
        "correct_normals = np.where((y_test_subset == 0) & (y_pred_subset == 0))[0]     # True Negatives\n",
        "false_alarms = np.where((y_test_subset == 0) & (y_pred_subset == 1))[0]        # False Positives\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.scatter(correct_anomalies, y_test_subset[correct_anomalies], color='green', label='Correct Anomaly', marker='x')\n",
        "plt.scatter(missed_anomalies, y_test_subset[missed_anomalies], color='red', label='Missed Anomaly', marker='o')\n",
        "plt.scatter(correct_normals, y_test_subset[correct_normals], color='blue', label='Correct Normal', marker='x')\n",
        "plt.scatter(false_alarms, y_test_subset[false_alarms], color='orange', label='False Alarm', marker='o')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Anomaly (0 = No, 1 = Yes)')\n",
        "plt.title('Anomaly Detection: Correct and Misclassified Predictions')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ibWSoJJxJA02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9lC5e4GMQ-Dy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}